{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgae have to sepearate into two folder Test and train\n",
    "\n",
    "#feature scaling in 100% compulsory in deep learning and must in computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impoert all the keras packeges\n",
    "from keras.models import Sequential   # two way representation either sequntial or Graph BUt CNN prefer Squntial\n",
    "from keras.layers import Convolution2D  #image thats why 2d if video then 3d\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "#convo 2d and convolution are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the convolution network\n",
    "classifier= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution step\n",
    "#Dense always used in the fully connected network which is used start in ANN\n",
    "\n",
    "#nb_filter= NUmber of feature want to create , if if we used one filter the one feature created--\n",
    "# (number of filter, Number of row and Number of column of feature detector)\n",
    "#32 means 64 feature map thats have dimention 3*3\n",
    "\n",
    "#input_shape is 1 if we worked with black white imgae and 3 if worked color image \n",
    "#3,256,256, 3 is channel and 256 and 256 is the other two dimension (expected color imgae) in theano in back-end\n",
    "\n",
    "#in tensorflow bakend ot reverse formate (64,64, 3) less because need less time in cpu\n",
    "#then inpiut activation function before that just sure not any negetive number in feature map if have then have to remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3,  input_shape=(64, 64, 3), activation='relu' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poling Step\n",
    "# Just reducing the size of feature map help to reduce the number of nodes\n",
    "# remember that size of the feature map dividing by 2 when we apply max-pooling\n",
    "#get more higher accuracy have to give nore input shape like 128 or 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " classifier.add(MaxPooling2D(pool_size=(2,2))) # most important and recomanded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How could we increase the accuracy level of Test_set\n",
    "# adding new convolution also help to decrease the gap between Traing and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Second Convolution_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when add new convolution layer dont need input_shape just need feature detector and shape with activation\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3),activation='relu' )) #convolution trick\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))      #max_pooling trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also 3rd convolution layer then the feature detector should be increase like 64\n",
    "# classifier.add(Convolution2D(64, 3, 3, input_shape=(64, 64, 3),activation='relu' )) #convolution trick\n",
    "# classifier.add(MaxPooling2D(pool_size=(2,2)))      #max_pooling trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening is basically all feature_map convert into a input layer like single vector\n",
    "#High number of feature map represent the more similerity to the input image\n",
    "# Q1: why dont we lose speatial structure by use this structure? A:Help taken from featureMap thats why not loss.and Max_polling\n",
    "# Q2 Why do not we take all value as input directly instead of doing this? A: Because we only take similer value not all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())  # no need any parameter here Keras will take care of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Step Full connection\n",
    "# output_dim represent number of node in hidden layer   #its now called ###units###\n",
    "#depend on input and out and we shouldn't take small number and not big here we take 32 feature that will contain tons of node\n",
    "#good practice to get power of 2 instead of 100 or any other value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=128, activation='relu'))   #input_layer not output_dim its now units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have only two outcome thats why used sigmoid if more than two then used softmax\n",
    "#1 means we expect the outcome dog or cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=1, activation='sigmoid'))   #output_layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All layer Complete and Time to SGD and loss function and Performance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile CNN\n",
    "# binary_cross_entropy function is used to also logistic regression\n",
    "#second reason is we have binary outcome\n",
    "#if we have three output then chose categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #accuracy always populara about that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Time to Image pre_processing Steps / Augmentation_steps\n",
    "# Have to prevent the overfiting do image preprocessing if we dont do then training get more accuracy than testing thats overfit.\n",
    "\n",
    "#### Important is that if we have less image then have to do image augmentation for better acciracy\n",
    "#it create many batches of image and apply rotating, shifting, flipping, shearing.\n",
    "#its a random transformation so model never find same picture an a batches\n",
    "#two part flow and flow_from directory method if directory have the dataset then used second one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8048 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,   #compulsory and feature scalling part that mean all image pixel value 0 and 1\n",
    "        shear_range=0.2,  #transvection  image\n",
    "        zoom_range=0.2,   #random zoom\n",
    "        horizontal_flip=True) #flip horizontally and also have vertical flip\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #preprocess the images\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',                   #used training set\n",
    "                                                target_size=(64, 64), #already we habe chose in previous\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')\n",
    "testing_set= test_datagen.flow_from_directory('dataset/test_set',     #used test set\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# device_name= tf.test.gpu_device_name()\n",
    "# if device_name !='/device:GPU:0':\n",
    "#     raise SystemError(\"GPU Device Not Found\")\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "  #GPU setup code for tensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(training_set,\n",
    "               steps_per_epoch=8000,   #depend on image size\n",
    "               epochs=10,\n",
    "               validation_data=testing_set,\n",
    "               validation_steps=2000)               #value accuracy mean test_set\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
